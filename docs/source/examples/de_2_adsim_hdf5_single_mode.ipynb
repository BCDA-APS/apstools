{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area Detector, Single mode, HDF5 file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**\n",
    "\n",
    "The [EPICS area detector](https://areadetector.github.io/master/index.html) software has a `Single` mode that reduces the configuration steps needed to acquire an image frame (?**or frames**?) and output a file.  Here, we show how to configure the EPICS controls, then acquire an image with [bluesky](https://blueskyproject.io/) and write it to an [HDF5](https://www.hdfgroup.org/solutions/hdf5) file.\n",
    "\n",
    "**Contents**\n",
    "\n",
    "- [EPICS Area Detector IOC](#EPICS-Area-Detector-IOC) is pre-built\n",
    "- [File Directories](#File-Directories) are different on IOC and bluesky workstation\n",
    "- [ophyd](#ophyd) to describe the hardware\n",
    "- [bluesky](#bluesky) for the measurement\n",
    "- [databroker](#databroker) to view the image\n",
    "- [punx](#punx) (not part of Bluesky) to look at the HDF5 file\n",
    "- [Recapitulation](#Recapitulation) - rendition with no explanations\n",
    "\n",
    "In other examples (such as AD with [default file names](./de_0_adsim_hdf5_basic.ipynb) or [custom file names](./de_1_adsim_hdf5_custom_names.ipynb)), we described the details of the area detector support.  Refer to those examples for the details.  Here, following the same general outline, we leverage that knowledge and proceed to the specifics for this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>TODO: Be sure to add these items</summary>\n",
    "***NOTE***\n",
    "\n",
    "This might need some customizations for `ophyd.areadetector.filestore_mixins.FileStoreHDF5IterativeWrite` to configure the staging properly and not include the `det.hdf1.capture` signal.  Also need to ensure `point_number` is written properly for databroker to retrieve the image from the HDF5 file.\n",
    "\n",
    "Implementation here should consider [#671](https://github.com/BCDA-APS/apstools/issues/671). The [NSLS-II area detector support](https://github.com/NSLS-II/nslsii/blob/9cd77e0aa24d59fddf534948b9b97dacb0832ed2/nslsii/ad33.py#L37) has some changes.  Here, new version-specific mixins would be appropriate.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPICS Area Detector IOC\n",
    "\n",
    "This example uses a prebuilt [ADSimDetector](https://areadetector.github.io/master/ADSimDetector/simDetector.html) driver, packaged in a [docker](https://www.docker.com/) image\n",
    "([prjemian/custom-synapps-6.2-ad-3.10](https://hub.docker.com/r/prjemian/custom-synapps-6.2-ad-3.10/tags)).  The [EPICS IOC](https://docs.epics-controls.org/projects/how-tos/en/latest/getting-started/creating-ioc.html) is configured with prefix `ad:` using the [bash shell script](https://github.com/prjemian/epics-docker/blob/main/v1.1/n6_custom_areaDetector/start_adsim.sh):\n",
    "\n",
    "```bash\n",
    "user@workstation:~$ start_adsim.sh ad\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "IOC = \"ad:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Directories\n",
    "\n",
    "Files from the IOC are mounted on the docker host in the directory `/tmp/docker_ioc/iocad`. The bluesky session runs on the docker host.\n",
    "\n",
    "system | file directory\n",
    "--- | ---\n",
    "area detector IOC | `/tmp`\n",
    "bluesky | `/tmp/docker_ioc/iocad/tmp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "# These paths are specific to how this IOC is implemented.\n",
    "AD_IOC_MOUNT_PATH = pathlib.Path(\"/tmp\")\n",
    "BLUESKY_MOUNT_PATH = pathlib.Path(\"/tmp/docker_ioc/iocad/tmp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define some structures that we will use when constructing the detector object.  The `IMAGE_DIR` describes our default choice for where to store image files.  We can change this at run time by changing thearea detector file writer's  `FilePath` PV (before starting image acquisition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"example/%Y/%m/%d\"  # our choice for file arrangement\n",
    "\n",
    "# MUST end with a `/`, pathlib will NOT provide it\n",
    "WRITE_PATH_TEMPLATE = f\"{AD_IOC_MOUNT_PATH / IMAGE_DIR}/\"\n",
    "READ_PATH_TEMPLATE = f\"{BLUESKY_MOUNT_PATH / IMAGE_DIR}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ophyd\n",
    "\n",
    "Here's a screen view of the configuration we want (`HDF` plugin on the left,\n",
    "`cam` plugin on the right):\n",
    "\n",
    "![Area Detector configuration for writing HDF5 files in Single mode](ad_hdf5_single_mode.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation\n",
    "\n",
    "Configure how [matplotlib](https://matplotlib.org/) charts will be displayed by in the notebook.\n",
    "\n",
    "We'll import additional libraries as needed by each of the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7fe388d62f40>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matplotlib graphics, choices include: inline, notebook, auto\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ion()  # turn on matplotlib plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cam\n",
    "\n",
    "The `cam` Device describes the EPICS area detector camera driver for this detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apstools.devices import CamMixin_V34\n",
    "from ophyd.areadetector import SimDetectorCam\n",
    "\n",
    "class TheDetectorCam(CamMixin_V34, SimDetectorCam):\n",
    "    \"\"\"Revise SimDetectorCam for ADCore revisions.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.stage_sigs.update(\n",
    "            dict(\n",
    "                acquire_time=0.01,\n",
    "                acquire_period=0.015,  # a wee bit longer than acquire_time\n",
    "                num_images=1,\n",
    "                num_exposures=1,  # Exp./image\n",
    "                wait_for_plugins=\"Yes\",\n",
    "                array_callbacks=\"Enable\",\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5\n",
    "\n",
    "The `hdf1` Device describes the HDF5 File Writing plugin for this detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ophyd.areadetector.filestore_mixins import FileStoreHDF5SingleIterativeWrite\n",
    "from ophyd.areadetector.plugins import HDF5Plugin_V34 as HDF5Plugin\n",
    "import warnings\n",
    "\n",
    "class OverrideFileStoreHDF5SingleIterativeWrite(FileStoreHDF5SingleIterativeWrite):\n",
    "    def stage(self):\n",
    "        # Do not press capture\n",
    "        if \"capture\" in self.stage_sigs:\n",
    "            print(f\"capture staged in {self}\")\n",
    "            self.stage_sigs.pop(\"capture\")\n",
    "        super().stage()\n",
    "\n",
    "class OverrideHDF5Plugin(HDF5Plugin):\n",
    "    def stage(self):\n",
    "        # Do not press capture\n",
    "        if \"capture\" in self.stage_sigs:\n",
    "            print(f\"capture staged in {self}\")\n",
    "            self.stage_sigs.pop(\"capture\")\n",
    "        super().stage()\n",
    "\n",
    "\n",
    "class TheHDF5Plugin(FileStoreHDF5SingleIterativeWrite, OverrideHDF5Plugin):\n",
    "    \"\"\"\n",
    "    Add data acquisition methods to HDF5Plugin.\n",
    "\n",
    "    * ``stage()`` - prepare device PVs befor data acquisition\n",
    "    * ``unstage()`` - restore device PVs after data acquisition\n",
    "    * ``generate_datum()`` - coordinate image storage metadata\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.stage_sigs.update(\n",
    "            dict(\n",
    "                array_callbacks=\"Disable\",\n",
    "                auto_increment=\"Yes\",\n",
    "                auto_save=\"Yes\",\n",
    "                blocking_callbacks=\"No\",\n",
    "                compression=\"zlib\",\n",
    "                lazy_open=\"Yes\",\n",
    "                store_perform=\"No\",\n",
    "                zlevel=6,\n",
    "            )\n",
    "        )\n",
    "        # capture is not used with Single mode\n",
    "        # parent.cam.array_callbacks is staged once in the cam\n",
    "        # create_directory must be set before file_path, which is set before staging\n",
    "        remove_these = \"\"\"\n",
    "            capture\n",
    "            array_counter\n",
    "            parent.cam.array_callbacks\n",
    "            create_directory\n",
    "        \"\"\".split()\n",
    "        for k in remove_these:\n",
    "            if k in self.stage_sigs:\n",
    "                self.stage_sigs.pop(k)\n",
    "\n",
    "    def stage(self):\n",
    "        # Do not press capture\n",
    "        if \"capture\" in self.stage_sigs:\n",
    "            warnings.warn(\"Do not use capture with write_mode='Single'\")\n",
    "            self.stage_sigs.pop(\"capture\")\n",
    "        super().stage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detector\n",
    "\n",
    "The detector class, a subclass of `DetectorBase`, brings together the detector driver `cam` and plugins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apstools.devices import SingleTrigger_V34\n",
    "from ophyd import ADComponent\n",
    "from ophyd.areadetector import DetectorBase\n",
    "from ophyd.areadetector.plugins import ImagePlugin_V34 as ImagePlugin\n",
    "\n",
    "class TheDetector(SingleTrigger_V34, DetectorBase):\n",
    "    \"\"\"\n",
    "    ADSimDetector\n",
    "\n",
    "    SingleTrigger:\n",
    "\n",
    "    * stop any current acquisition\n",
    "    * sets image_mode to 'Multiple'\n",
    "    \"\"\"\n",
    "\n",
    "    cam = ADComponent(TheDetectorCam, \"cam1:\")\n",
    "    hdf1 = ADComponent(\n",
    "        TheHDF5Plugin,\n",
    "        \"HDF1:\",\n",
    "        write_path_template=WRITE_PATH_TEMPLATE,\n",
    "        read_path_template=READ_PATH_TEMPLATE,\n",
    "    )\n",
    "    image = ADComponent(ImagePlugin, \"image1:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `FileStoreHDF5IterativeWrite` not found.\n"
     ]
    }
   ],
   "source": [
    "FileStoreHDF5IterativeWrite?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the above setup, create the Python detector object, `adsimdet` and wait for it to connect with EPICS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adsimdet = TheDetector(IOC, name=\"adsimdet\")\n",
    "adsimdet.wait_for_connection(timeout=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that all plugins used by the IOC have been defined in the Python structure.  Expect that this function returns an empty list: `[]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adsimdet.missing_plugins()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must configure `adsimdet` so the HDF5 plugin (by its attribute name `hdf1`) will be called during `adsimdet.read()`, as used by data acquisition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adsimdet.read_attrs.append(\"hdf1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the HDF5 plugin so it will create up to 5 subdirectories for the image directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adsimdet.hdf1.create_directory.put(-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Prime* the HDF5 plugin, if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apstools.devices import AD_plugin_primed\n",
    "from apstools.devices import AD_prime_plugin2\n",
    "\n",
    "# this step is needed for ophyd\n",
    "if not AD_plugin_primed(adsimdet.hdf1):\n",
    "    print(f\"Priming {adsimdet.hdf1.dotted_name}\")\n",
    "    AD_prime_plugin2(adsimdet.hdf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how `adsim` is [staged](https://blueskyproject.io/ophyd/user_v1/explanations/staging.html) (configured for data acquisition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('cam.acquire', 0), ('cam.image_mode', 1)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adsimdet.stage_sigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('acquire_time', 0.01),\n",
       "             ('acquire_period', 0.015),\n",
       "             ('num_images', 1),\n",
       "             ('num_exposures', 1),\n",
       "             ('wait_for_plugins', 'Yes'),\n",
       "             ('array_callbacks', 'Enable')])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adsimdet.cam.stage_sigs[\"num_images\"] = 1\n",
    "adsimdet.cam.stage_sigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('enable', 1),\n",
       "             ('blocking_callbacks', 'No'),\n",
       "             ('auto_increment', 'Yes'),\n",
       "             ('auto_save', 'Yes'),\n",
       "             ('num_capture', 0),\n",
       "             ('file_template', '%s%s_%6.6d.h5'),\n",
       "             ('file_write_mode', 'Single'),\n",
       "             ('array_callbacks', 'Disable'),\n",
       "             ('compression', 'zlib'),\n",
       "             ('lazy_open', 'Yes'),\n",
       "             ('store_perform', 'No'),\n",
       "             ('zlevel', 6)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adsimdet.hdf1.stage_sigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "adsimdet.stage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just stop right here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "adsimdet.unstage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bluesky\n",
    "\n",
    "Within the [Bluesky framework](https://blueskyproject.io/), [bluesky](https://blueskyproject.io/bluesky) is the package that orchestrates the data acquisition steps, including where to direct acquired data for storage.  [Later](#databroker), we'll use [databroker](https://blueskyproject.io/databroker) to access the image data.\n",
    "\n",
    "First, setup the RunEngine object `RE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bluesky\n",
    "\n",
    "RE = bluesky.RunEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### databroker (as RunEngine subscriber)\n",
    "\n",
    "Setup the databroker (with a temporary databroker catalog) as a subscriber to the documents published from the bluesky `RunEngine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import databroker\n",
    "\n",
    "cat = databroker.temp().v2  # or use your own catalog: databroker.catalog[\"CATALOG_NAME\"]\n",
    "cat = databroker.catalog[\"training\"]\n",
    "RE.subscribe(cat.v1.insert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Take an image with the area detector***\n",
    "\n",
    "Finally, we are ready to acquire an image.  We'll use the standard bluesky [count()](https://blueskyproject.io/bluesky/generated/bluesky.plans.count.html#bluesky.plans.count) plan.  Also add some metadata about this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bluesky.plans as bp\n",
    "\n",
    "uids = RE(\n",
    "    bp.count([adsimdet],\n",
    "    md=dict(\n",
    "        title=\"Area Detector, Single mode, HDF5 file\",\n",
    "        purpose=\"image\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## databroker\n",
    "\n",
    "Here we show how to access and display the acquired image using databroker as the interface to the data files and run metadata.\n",
    "\n",
    "First, find the run we just acquired.  We'll index to that run using the `uid` returned by the above call to `RE()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlueskyRun\n",
       "  uid='1a942a8c-2cc7-455b-84c3-60bdbc1b561d'\n",
       "  exit_status='success'\n",
       "  2022-09-29 15:34:26.937 -- 2022-09-29 15:34:27.009\n",
       "  Streams:\n",
       "    * primary\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = cat.v2[uids[0]]\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get the image frame from the run***\n",
    "\n",
    "Combining several steps into one line, extract the image frame from the run.  We know the image data is in the `primary` stream, that the image is recorded under the name `\"adsimdet_image\"` (or `adsimdet.image.name`), and the `image` frame is the last two indices.\n",
    "\n",
    "Import [hdf5plugin](https://hdf5plugin.readthedocs.io), a library that supports advanced compression modes for data in HDF5 files.  (We don't have to call any of its modules directly.  The `import hdf5plugin` will install entry points needed when the supported compression modes are called.)  We did not need this previously since it was the IOC that wrote the  HDF5 file with the chosen compression mode.\n",
    "\n",
    "NOTE: Any Python client that reads data compressed with these compression modes will also need to import the `hdf5plugin` library, or provide alternative support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdf5plugin  # required for LZ4, Blosc, and other compression codecs\n",
    "\n",
    "print(run.primary._resources)\n",
    "ds = run.primary._ds\n",
    "image = ds[adsimdet.image.name]\n",
    "frame = image[0][0]\n",
    "# frame = run.primary.read()[adsimdet.image.name][0][0]\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the image\n",
    "\n",
    "The `frame` is an [xarray Dataset](https://docs.xarray.dev/en/stable/generated/xarray.Dataset.html), which has a method to visualize the data as shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.plot.pcolormesh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where is the image file on disk?\n",
    "\n",
    "So far, we have not had to know the name of the file on disk with the image data.  Still, we can learn about that from the run's metadata, by querying one of its internal structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.primary._resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This information has shown the path to the image file *as seen from the bluesky workstation's file system.*  We can parse this structure for the file name. In this case, the file is found since the `resource_path` is written relative to the `READ_PATH_TEMPLATE` defined [above](#File-Directories).\n",
    "\n",
    "This is an important distinction since the IOC and bluesky see the same file on different directory paths, as described [above](#File-Directories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsrc = run.primary._resources[0]\n",
    "file_name = pathlib.Path(f\"{rsrc['root']}{rsrc['resource_path']}\")\n",
    "print(f\"{file_name.exists()=}\\n{file_name=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, get the name of the image file on the bluesky (local) workstation from the `adsimdet` object.\n",
    "\n",
    "NOTE: This method relies on information currently defined in EPICS, via the `adsimdet.hdf1`, so it may not be successful if the HDF plugin has been changed since the image was acquired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apstools.devices import AD_full_file_name_local\n",
    "\n",
    "local_file_name = AD_full_file_name_local(adsimdet.hdf1)\n",
    "print(f\"{local_file_name.exists()=}\\n{local_file_name=}\")\n",
    "local_file_name == file_name  # compare the two names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## punx\n",
    "\n",
    "Next, we demonstrate access to the HDF5 image file using the [punx](https://punx.readthedocs.io) program, showing the tree structure of the data file (the image data may be found at HDF5 address `/entry/data/data`, another reference to the exact same data is found at `/entry/instrument/detector/data`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apstools.utils import unix\n",
    "\n",
    "for line in unix(f\"punx tree {file_name}\"):\n",
    "    print(line.decode().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recapitulation\n",
    "\n",
    "Let's gather the above parts together as one would usually write code.  First, all the imports, constants, and classes.\n",
    "\n",
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f38aef175fb08dfc130a7d9bb9234f0792dc9ad861f95b6c05aedd1b380356e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
